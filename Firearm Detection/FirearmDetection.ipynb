{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FirearmDetection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yXTD9OZzVmze9mfaUvhcH-3fwnN1pxZ7","authorship_tag":"ABX9TyNwhk7GlKRxHQ23ljl6lKhy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%cd /content/drive/MyDrive/TARP/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJvFm1lBef_k","executionInfo":{"status":"ok","timestamp":1646915523439,"user_tz":-330,"elapsed":343,"user":{"displayName":"Arvindh A R 19BAI1106","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02465341428994948624"}},"outputId":"5ef28704-c05c-4189-9374-ed4aee513b87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TARP/data\n"]}]},{"cell_type":"code","source":["import torchvision"],"metadata":{"id":"Pqw-LCj7auml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"81CRf_gFaMA7","executionInfo":{"status":"ok","timestamp":1651136894580,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arvindh A R 19BAI1106","userId":"02465341428994948624"}},"outputId":"04c9525b-2f7c-4f19-bedd-e55daa9ed12e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.11.0+cu113'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJcRtF2ndq5T"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from numpy.core.defchararray import join, mod\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import albumentations as A\n","import os\n","import torch\n","from torch._C import device\n","from torch.autograd.grad_mode import F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.rpn import AnchorGenerator\n","from PIL import Image\n","from torchvision import transforms as torchtrans  "]},{"cell_type":"code","source":["labels_path = 'Labels'\n","imgs_path = 'Images'"],"metadata":{"id":"qNSBODHgeQbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","class gun(Dataset):\n","    def __init__(self,imgs_path,labels_path):\n","\n","        self.imgs_path = imgs_path\n","        self.labels_path = labels_path\n","        self.img_name = [img for img in sorted(os.listdir(self.imgs_path))]\n","        self.label_name = [label for label in sorted(os.listdir(self.labels_path))]\n","\n","    def __getitem__(self,idx):\n","\n","        image_path = os.path.join(self.imgs_path,str(self.img_name[idx]))\n","        img = cv2.imread(image_path)\n","        \n","        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        img_res = img_rgb/255\n","        img_res = torch.as_tensor(img_res).to(device)\n","        img_res = img_res.permute(2, 0, 1)\n","        \n","        label_name = self.img_name[idx][:-4] + \"txt\"\n","        label_path = os.path.join(self.labels_path,str(label_name))\n","        with open(label_path, 'r') as label_file:\n","            l_count = int(label_file.readline())\n","            box = []\n","            for i in range(l_count):\n","                box.append(list(map(int, label_file.readline().split())))\n","\n","        target={}\n","        target[\"boxes\"] = torch.as_tensor(box).to(device)\n","        area = []\n","        for i in range(len(box)):\n","           \n","            a = (box[i][2] - box[i][0]) * (box[i][3] - box[i][1])\n","            area.append(a)\n","        target[\"area\"] = torch.as_tensor(area).to(device)\n","        labels = []\n","        for i in range(len(box)):\n","            labels.append(1)\n","\n","        target[\"image_id\"] = torch.as_tensor([idx]).to(device)\n","        target[\"labels\"] = torch.as_tensor(labels, dtype = torch.int64).to(device)\n","\n","\n","        return img_res,target\n","\n","    def __len__(self):\n","        return len(self.img_name)"],"metadata":{"id":"tvNefGP8eZpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def model(num):\n","    model = fasterrcnn_resnet50_fpn(pretrained=True)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(\n","        in_features, num)\n","    return model\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))"],"metadata":{"id":"xy2WIe3yeaXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gun_data = gun(imgs_path, labels_path)\n","gun_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBFE6Ew5fXpv","executionInfo":{"status":"ok","timestamp":1646915534435,"user_tz":-330,"elapsed":2622,"user":{"displayName":"Arvindh A R 19BAI1106","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02465341428994948624"}},"outputId":"2973bedf-4e60-4d6b-a3a7-c05f20ec0b56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.gun at 0x7f9f58ff75d0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["data_load = DataLoader(gun_data, batch_size=5,\n","                       shuffle=True, num_workers=0, collate_fn=collate_fn)\n","num_class = 2\n","model = model(num_class)\n","model.to(device)\n","num_epoch = 10\n","param = [param for param in model.parameters() if param.requires_grad]\n","optimizer = torch.optim.SGD(param,lr=0.01,momentum=0.9)\n","lr_scheduler = None\n","for epoch in range(num_epoch):\n","    loss_num = 0\n","    model.train()\n","    for img, target in data_load:\n","        loss_dic = model(img, target)\n","        loss = sum(loss for loss in loss_dic.values())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        loss_num += loss\n","    if lr_scheduler is not None:\n","        lr_scheduler.step()\n","    print(\"epoch:{},loss:{}\".format(epoch, loss_num))"],"metadata":{"id":"aBpKyBSSfggF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cpu_device = torch.device(\"cpu\")\n","model = model.eval()\n","test_path = 'Images'\n","test_data = gun(imgs_path, labels_path)\n","img,tar = test_data[10] \n","input = []\n","input.append(img)\n","outputs = model(input)"],"metadata":{"id":"2VCnMsXjh1pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","boxes = outputs[0][\"boxes\"].detach().numpy().astype(np.int32)\n","id = np.argmax(outputs[0][\"scores\"].detach().numpy())\n","xmin = boxes[id][0]\n","xmax = boxes[id][2]\n","ymin = boxes[id][1]\n","ymax = boxes[id][3]\n","img1 = np.array(img.permute(1, 2, 0).to(torch.device(\"cpu\")))\n","\n","fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","for box in boxes:\n","    cv2.rectangle(img1,(xmin,ymin),(xmax,ymax),(220,0,0),1)\n","    \n","ax.set_axis_off()\n","ax.imshow(img1)\n","outputs "],"metadata":{"id":"nEENknSih1wd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.patches as patches\n","def apply_nms(orig_prediction, iou_thresh=None):\n","    \n","    # torchvision returns the indices of the bboxes to keep\n","    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n","    \n","    final_prediction = orig_prediction\n","    final_prediction['boxes'] = final_prediction['boxes'][keep]\n","    final_prediction['scores'] = final_prediction['scores'][keep]\n","    final_prediction['labels'] = final_prediction['labels'][keep]\n","\n","    \n","    return final_prediction"],"metadata":{"id":"d6FIIDEUh1ze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def torch_to_pil(img):\n","    return torchtrans.ToPILImage()(img).convert('RGB')\n","\n","\n","def plot_img_bbox(img, target):\n","    # plot the image and bboxes\n","    # Bounding boxes are defined as follows: x-min y-min width height\n","    fig, a = plt.subplots(1,1)\n","    fig.set_size_inches(5,5)\n","    a.imshow(img)\n","    for box in (target['boxes']):\n","        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n","        rect = patches.Rectangle((x, y),\n","                                 width, height,\n","                                 linewidth = 2,\n","                                 edgecolor = 'r',\n","                                 facecolor = 'none')\n","\n","        # Draw the bounding box on top of the image\n","        a.add_patch(rect)\n","    plt.show()"],"metadata":{"id":"myZeozoMh12i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nms_prediction = apply_nms(outputs[0], iou_thresh=0.7)\n","print('NMS APPLIED MODEL OUTPUT')\n","plot_img_bbox(torch_to_pil(img), nms_prediction)"],"metadata":{"id":"zx_X0itSh16H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KONG-0KVh19W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"aYPf57F8h2A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"J8LuMc3sh2EU"},"execution_count":null,"outputs":[]}]}